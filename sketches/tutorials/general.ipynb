{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"../../.venv\")\n",
    "\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo-1106', max_tokens=300, temperature=1)\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "\n",
    "dspy.settings.configure(lm=turbo, rm=colbertv2_wiki17_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pydantic : packing I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Signature (with pydantic-tuned \"input\" and \"output\") ############################################################\n",
    "\n",
    "class Input(BaseModel): # Packing 2 inputs into 1 object\n",
    "    context: str = Field(description=\"The context for the question\")\n",
    "    query: str = Field(description=\"The question to be answered\")\n",
    "\n",
    "class Output(BaseModel): # Puting a 'confidence' output together with the answer\n",
    "    answer: str = Field(description=\"The answer for the question\")\n",
    "    confidence: float = Field(ge=0, le=1, description=\"The confidence score for the answer\") # Enforcing [0,1]\n",
    "\n",
    "class QASignature(dspy.Signature): # Now, we compose a class for the signature\n",
    "    \"\"\"Answer the question based on the context and query provided, and on the scale of 10 tell how confident you are about the answer.\"\"\"\n",
    "    input: Input = dspy.InputField()\n",
    "    output: Output = dspy.OutputField()\n",
    "\n",
    "# Module ###########################################################################################################\n",
    "\n",
    "predictor = dspy.TypedPredictor(QASignature) # 'dspy.TypedPredictor(\"input:Input -> output:Output\")' = inline signature\n",
    "# or predictor = dspy.TypedChainOfThought(QASignature)\n",
    "\n",
    "doc_query_pair = Input(\n",
    "    context=\"The quick brown fox jumps over the lazy dog\",\n",
    "    query=\"What does the fox jumps over?\",\n",
    ")\n",
    "\n",
    "prediction = predictor(input=doc_query_pair) # predictor(doc_query_pair) fails because it expects a dictionary\n",
    "\n",
    "prediction.output.answer\n",
    "prediction.output.confidence\n",
    "prediction.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pydantic I/O + Module via decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(answer='the lazy dog', confidence=0.9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pydantic I/O #####################################################################\n",
    "\n",
    "class Input(BaseModel): # Packing 2 inputs into 1 object\n",
    "    context: str = Field(description=\"The context for the question\")\n",
    "    query: str = Field(description=\"The question to be answered\")\n",
    "\n",
    "class Output(BaseModel): # Puting a 'confidence' output together with the answer\n",
    "    answer: str = Field(description=\"The answer for the question\")\n",
    "    confidence: float = Field(ge=0, le=1, description=\"The confidence score for the answer\") # Enforcing [0,1]\n",
    "\n",
    "# Module ###########################################################################################################\n",
    "\n",
    "@dspy.predictor # or \"@dspy.cot\"\n",
    "def predictor(doc_query_pair: Input) -> Output:\n",
    "    \"\"\"Answer the question based on the context and query provided, and on the scale of 0-1 tell how confident you are about the answer.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Run ##############################################################################################################\n",
    "\n",
    "doc_query_pair = Input(\n",
    "    context=\"The quick brown fox jumps over the lazy dog\",\n",
    "    query=\"What does the fox jumps over?\",\n",
    ")\n",
    "\n",
    "prediction = predictor(doc_query_pair=doc_query_pair) # predictor(doc_query_pair) fails because it expects a dictionary\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic 'Example' Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These declarations are equivalent\n",
    "\n",
    "article_summary = dspy.Example(\n",
    "    context=\"This is an article.\", question=\"This is a question?\",\n",
    "    answer=\"This is an answer.\", rationale= \"This is a rationale.\"\n",
    ").with_inputs(\"context\", \"question\")\n",
    "\n",
    "article_summary.inputs() # inputs\n",
    "article_summary.labels() # outputs\n",
    "\n",
    "# print(article_summary.inputs().context)\n",
    "# print(article_summary.context)\n",
    "\n",
    "article_summary.new_attribute = True\n",
    "\n",
    "# article_summary = dspy.Example(\n",
    "#     context=\"This is an article.\", question=\"This is a question?\",\n",
    "#     answer=\"This is an answer.\", rationale= \"This is a rationale.\"\n",
    "# ).without(\"answer\", \"rationale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic CoT + 'hint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Blue'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "generate_answer = dspy.ChainOfThoughtWithHint(BasicQA)\n",
    "\n",
    "# Call the predictor alongside a hint.\n",
    "question='What is the color of the sky?'\n",
    "hint = \"It's what you often see during a sunny day.\"\n",
    "pred = generate_answer(question=question, hint=hint)\n",
    "\n",
    "question\n",
    "pred.rationale\n",
    "pred.answer\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Factuality Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactJudge(dspy.Signature):\n",
    "    \"\"\"Judge if the answer is factually correct based on the context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"Context for the prediciton\")\n",
    "    question = dspy.InputField(desc=\"Question to be answered\")\n",
    "    answer = dspy.InputField(desc=\"Answer for the question\")\n",
    "    factually_correct = dspy.OutputField(desc=\"Is the answer factually correct based on the context?\", prefix=\"Factual[Yes/No]:\")\n",
    "\n",
    "judge = dspy.ChainOfThought(FactJudge)\n",
    "\n",
    "def factuality_metric(example, pred):\n",
    "    factual = judge(context=example.context, question=example.question, answer=pred.answer)\n",
    "    return int(factual==\"Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Knowledge Management Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/longformqa/longformqa_assertions.ipynb#scrollTo=fKc-ij_jopBs\n",
    "https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/quiz/quiz_assertions.ipynb\n",
    "https://colab.research.google.com/github/stanfordnlp/dspy/blob/main/examples/tweets/tweets_assertions.ipynb\n",
    "https://colab.research.google.com/drive/1CpsOiLiLYKeGrhmq579_FmtGsD5uZ3Qe#scrollTo=hVrLgbZvbJ97\n",
    "https://github.com/stanfordnlp/dspy/blob/main/examples/tweets/tweet_metric.py\n",
    "https://github.com/saifulhaq95/DSPy-Indic/blob/main/indicxlni.ipynb\n",
    "https://github.com/stanfordnlp/dspy/blob/main/examples/nli/scone/scone.ipynb\n",
    "https://github.com/stanfordnlp/dspy/blob/main/skycamp2023.ipynb\n",
    "https://github.com/stanfordnlp/dspy/blob/main/examples/qa/hotpot/multihop_finetune.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Predict</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">StringSignature</span><span style=\"font-weight: bold\">(</span>question -&gt; answer\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Given the fields `question`, produce the fields `answer`.'</span>\n",
       "    question = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Question:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${question}'</span><span style=\"font-weight: bold\">})</span>\n",
       "    answer = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'Answer:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'${answer}'</span><span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPredict\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mStringSignature\u001b[0m\u001b[1m(\u001b[0mquestion -> answer\n",
       "    \u001b[33minstructions\u001b[0m=\u001b[32m'Given the fields `question`, produce the fields `answer`.'\u001b[0m\n",
       "    question = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'input'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \n",
       "\u001b[32m'Question:'\u001b[0m, \u001b[32m'desc'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    answer = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'output'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \n",
       "\u001b[32m'Answer:'\u001b[0m, \u001b[32m'desc'\u001b[0m: \u001b[32m'$\u001b[0m\u001b[32m{\u001b[0m\u001b[32manswer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Predict</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiClass</span><span style=\"font-weight: bold\">(</span>sentence -&gt; data_type\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Classifiy the given data into Address, Human's Name and Age\"</span>\n",
       "    sentence = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'data to be classified'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'input'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Sentence:'</span><span style=\"font-weight: bold\">})</span>\n",
       "    data_type = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Field</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span> <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">json_schema_extra</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'desc'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'falls in one of categories'</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'__dspy_field_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'output'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Data Type:'</span><span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPredict\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mMultiClass\u001b[0m\u001b[1m(\u001b[0msentence -> data_type\n",
       "    \u001b[33minstructions\u001b[0m=\u001b[32m\"Classifiy\u001b[0m\u001b[32m the given data into Address, Human's Name and Age\"\u001b[0m\n",
       "    sentence = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'desc'\u001b[0m: \u001b[32m'data to be classified'\u001b[0m, \n",
       "\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'input'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \u001b[32m'Sentence:'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "    data_type = \u001b[1;35mField\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mjson_schema_extra\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'desc'\u001b[0m: \u001b[32m'falls in one of categories'\u001b[0m, \n",
       "\u001b[32m'__dspy_field_type'\u001b[0m: \u001b[32m'output'\u001b[0m, \u001b[32m'prefix'\u001b[0m: \u001b[32m'Data Type:'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence = \"it's a charming and often affecting journey.\"  # example from the SST-2 dataset.\n",
    "# classify = dspy.Predict('sentence -> sentiment')\n",
    "# classify(sentence=sentence).sentiment\n",
    "\n",
    "# question = \"What's something great about the ColBERT retrieval model?\"\n",
    "# # 1) Declare with a signature, and pass some config.\n",
    "# classify = dspy.ChainOfThought('question -> answer', n=5)\n",
    "# # 2) Call with input argument.\n",
    "# response = classify(question=question)\n",
    "# # 3) Access the outputs.\n",
    "# response.completions.answer\n",
    "\n",
    "# import dspy\n",
    "# context = [\"Roses are red.\", \"Violets are blue\"]\n",
    "# question = \"What color are roses?\"\n",
    "# @dspy.predictor # automaticaly generates a dspy.TypedPredictor\n",
    "# def generate_answer(self, context: list[str], question) -> str:\n",
    "#     \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "#     pass\n",
    "# generate_answer(context=context, question=question)\n",
    "\n",
    "# import dspy\n",
    "\n",
    "# context = [\"Roses are red.\", \"Violets are blue\"]\n",
    "# question = \"What color are roses?\"\n",
    "# @dspy.cot # automaticaly generates a dspy.TypedPredictor\n",
    "# def generate_answer(self, context: list[str], question) -> str:\n",
    "#     \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "#     pass\n",
    "# generate_answer(context=context, question=question)\n",
    "\n",
    "# class SimplifiedBaleen(dspy.Module):\n",
    "#     def __init__(self, passages_per_hop=2, max_hops=2):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "#         self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "#         self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "#         self.max_hops = max_hops\n",
    "\n",
    "#     def forward(self, question):\n",
    "#         context = []\n",
    "#         prev_queries = [question]\n",
    "\n",
    "#         for hop in range(self.max_hops):\n",
    "#             query = self.generate_query[hop](context=context, question=question).query\n",
    "#             prev_queries.append(query)\n",
    "#             passages = self.retrieve(query).passages\n",
    "#             context = deduplicate(context + passages)\n",
    "        \n",
    "#         pred = self.generate_answer(context=context, question=question)\n",
    "#         pred = dspy.Prediction(context=context, answer=pred.answer)\n",
    "#         return pred\n",
    "\n",
    "# baleen = SimplifiedBaleen()\n",
    "\n",
    "# baleen(question = \"Which award did Gary Zukav's first book receive?\")\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     \"Assert\": {\n",
    "#         \"parameter\": {\n",
    "#             \"constraint\": \"Boolean Validation check Outcome\",\n",
    "#             \"msg\": \"User Defined Error message for correction\",\n",
    "#             \"backtrack\": \"Specifies target module (usually the last) for retry attempts upon failure.\"\n",
    "#         },\n",
    "#         \"behaviour\": \"Initiates retry upon failure, dynamic signature modification of the pipeline. If no improvement, halts. Adds fields like 'past_output' that failed validation, 'instruction' which is provided by the user to recover.\",\n",
    "#         \"application\": \"Useful as checkers / gate-keepers in production code\"\n",
    "#     },\n",
    "#     \"Suggest\": {\n",
    "#         \"parameter\": {\n",
    "#             \"constraint\": \"Boolean Validation check Outcome\",\n",
    "#             \"msg\": \"User Defined Error message for correction\",\n",
    "#             \"backtrack\": \"Specifies target module (usually the last) for retry attempts upon failure.\"\n",
    "#         },\n",
    "#         \"behaviour\": \"Encourages self-refinement without hardstops, logs failure after backtracking attempts\",\n",
    "#         \"application\": \"Useful as guide or helpers in evaluation phase.\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# qa_pred = dspy.Predict('question -> answer')\n",
    "# print(qa_pred)\n",
    "\n",
    "# class MultiClass(dspy.Signature):\n",
    "#     \"\"\"Classifiy the given data into Address, Human's Name and Age\"\"\"\n",
    "#     sentence = dspy.InputField(desc=\"data to be classified\")\n",
    "#     data_type = dspy.OutputField(desc=\"falls in one of categories\")\n",
    "\n",
    "# pred_class = dspy.Predict(MultiClass)\n",
    "# print(pred_class)\n",
    "\n",
    "# get_json = Predict('required_data -> json_output')\n",
    "# prompt = \"provide one example of Address, Location, Human Name, Building Name and Amount\"\n",
    "# with context(lm=turbo):\n",
    "#     resp = get_json(required_data=prompt)\n",
    "#     print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor.predictor = Predict(StringSignature(context, question -> reasoning, generate_answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=list[str] required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Context:', 'desc': '${context}'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the generate_answer}. We ...', '__dspy_field_type': 'output'})\n",
      "    generate_answer = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Generate Answer:', 'desc': '${generate_answer}'})\n",
      "))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Roses are red.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dspy\n",
    "\n",
    "# context = [\"Roses are red.\", \"Violets are blue\"]\n",
    "# question = \"What color are roses?\"\n",
    "\n",
    "# @dspy.cot\n",
    "# def generate_answer(self, context: list[str], question) -> str:\n",
    "#     \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "#     pass\n",
    "\n",
    "# print(generate_answer)\n",
    "\n",
    "# generate_answer(context=context, question=question)\n",
    "\n",
    "# # gpt3_turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Tweeter(dspy.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.generate_tweet = dspy.ChainOfThought(GenerateTweet)\n",
    "\n",
    "#     def forward(self, question, answer):\n",
    "#         context = []\n",
    "#         max_hops = 2\n",
    "#         passages_per_hop = 3\n",
    "#         generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "#         retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "#         for hop in range(max_hops):\n",
    "#             query = generate_query[hop](context=context, question=question).query\n",
    "#             passages = retrieve(query).passages\n",
    "#             context = deduplicate(context + passages)\n",
    "#         generated_tweet = self.generate_tweet(question=question, context=context).tweet\n",
    "#         return dspy.Prediction(generated_tweet, context=context)\n",
    "\n",
    "#     dspy.Suggest(has_no_hashtags(generated_tweet), \"Please revise the tweet to remove hashtag phrases following it.\")\n",
    "#     dspy.Suggest(is_within_length_limit(generated_tweet, 280), \"Please ensure the tweet is within {280} characters.\")\n",
    "#     dspy.Suggest(has_correct_answer(generated_tweet, answer), \"The tweet does not include the correct answer to the question. Please revise accordingly.\")\n",
    "#     dspy.Suggest(is_assessment_yes(engaging_assessment.assessment_answer), \"The text is not engaging enough. Please revise to make it more captivating.\")\n",
    "#     dspy.Suggest(is_assessment_yes(faithful_assessment.assessment_answer), \"The text contains unfaithful elements or significant facts not in the content. Please revise for accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "No RM is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Call the retriever on a particular query.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m retrieve \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mRetrieve(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m topK_passages \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpassages\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretrieve\u001b[38;5;241m.\u001b[39mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passages for question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, passage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(topK_passages):\n",
      "File \u001b[1;32mg:\\Mi unidad\\SONY-GATEWAY\\MaLB-SC-generation-module\\.venv\\Lib\\site-packages\\dspy\\retrieve\\retrieve.py:30\u001b[0m, in \u001b[0;36mRetrieve.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Mi unidad\\SONY-GATEWAY\\MaLB-SC-generation-module\\.venv\\Lib\\site-packages\\dspy\\retrieve\\retrieve.py:39\u001b[0m, in \u001b[0;36mRetrieve.forward\u001b[1;34m(self, query_or_queries, k, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# print(queries)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# TODO: Consider removing any quote-like markers that surround the query too.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk\n\u001b[1;32m---> 39\u001b[0m passages \u001b[38;5;241m=\u001b[39m \u001b[43mdsp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieveEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Prediction(passages\u001b[38;5;241m=\u001b[39mpassages)\n",
      "File \u001b[1;32mg:\\Mi unidad\\SONY-GATEWAY\\MaLB-SC-generation-module\\.venv\\Lib\\site-packages\\dsp\\primitives\\search.py:50\u001b[0m, in \u001b[0;36mretrieveEnsemble\u001b[1;34m(queries, k, by_prob, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves passages from the RM for each query in queries and returns the top k passages\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mbased on the probability or score.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mrm:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo RM is loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mreranker:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retrieveRerankEnsemble(queries, k)\n",
      "\u001b[1;31mAssertionError\u001b[0m: No RM is loaded."
     ]
    }
   ],
   "source": [
    "# query='When was the first FIFA World Cup held?'\n",
    "\n",
    "# # Call the retriever on a particular query.\n",
    "# retrieve = dspy.Retrieve(k=3)\n",
    "# topK_passages = retrieve(query).passages\n",
    "\n",
    "# print(f\"Top {retrieve.k} passages for question: {query} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "# for idx, passage in enumerate(topK_passages):\n",
    "#     print(f'{idx+1}]', passage, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHopQA(dspy.Module):\n",
    "#     def __init__(self):\n",
    "#         self.retrieve = dspy.Retrieve(k=3)\n",
    "#         self.gen_query = dspy.ChainOfThought(\"context, question -> query\")\n",
    "#         self.gen_answer = dspy.ChainOfThought(\"context, query -> answer\")\n",
    "#     def forward(self, question):\n",
    "#         context = []\n",
    "#         for hop in range(2):\n",
    "#             query = self.gen_query(context=context, question=question).query\n",
    "#             context+= self.retrieve(query).passages\n",
    "#         return self.gen_answer(context=context, question=question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
